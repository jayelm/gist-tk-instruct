{
    "freeze_decoder": true,
    "run_name": "large-gist-10-freeze-decoder",
    "gist_condition": "gist",
    "num_gist_tokens": 10,
    "model_name_or_path": "google/t5-large-lm-adapt",
    "per_device_train_batch_size": 2,
    "per_device_eval_batch_size": 2,
    "gradient_accumulation_steps": 8,
    "do_train": true,
    "do_predict": true,
    "predict_with_generate": true,
    "max_source_length": 1024,
    "max_target_length": 128,
    "generation_max_length": 128,
    "max_num_instances_per_task": 100,
    "max_num_instances_per_eval_task": 100,
    "add_task_name": false,
    "add_task_definition": true,
    "num_pos_examples": 2,
    "num_neg_examples": 0,
    "add_explanation": false,
    "tk_instruct": false,
    "data_dir": "data/splits/default",
    "task_dir": "data/tasks",
    "output_dir": "exp/large-gist-10",
    "overwrite_output_dir": true,
    "cache_dir": "./cache/",
    "overwrite_cache": true,
    "learning_rate": 5e-05,
    "num_train_epochs": 4,
    "lr_scheduler_type": "constant",
    "warmup_steps": 0,
    "logging_strategy": "steps",
    "logging_steps": 500,
    "evaluation_strategy": "steps",
    "eval_steps": 1000,
    "save_strategy": "steps",
    "load_best_model_at_end": true,
    "save_total_limit": 1,
    "save_steps": 1000,
    "report_to": "none"
}
